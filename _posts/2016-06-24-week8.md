---
layout: post
title: "Week 8: Interactive training"
category:
- gsoc16
permalink: gsoc16/week/8/
meta_description: 'GSOC2016: Week 8'
browser_title: 'GSOC2016: Week 8'
---


This week I was working on implementing interactive training mode.


This week I learnt about python parallel computing in python. I implemented simple things (ipywidgets button and a running thread),  I wanted to generalize this to TMVA but it
didn't worked. I learnt that this is because of GIL, and to enable threading to `TMVA.Factory.TrainAllMethods` I need to set `_threaded` flag to true for every function. Using
this flag seemed to solve my problem, I was able to run ROOT methods on thread, but when I tried to do the same with `TMVA.Factory.TrainAllMethods` it doesn't work. I also tried
run a similar code as a simple python process and there everything worked fine. To be able to work on this weeks task, I created a function to simulate the training process.

## MyTrain

I added this function to Factory, this just calls MyBigLoop if the method is MLP.

## MyBigLoop

This is a member function of MethodMLP: contains a loop and calculates some function and goes to sleep to simulate the long calculations of training MLP.

## Conclusion about what I will need from MethodMLP
I need 2 private variable:

* `Int_t fCurrentEpoch`: I need to set this variable to current epoch in training method

* `bool fExitFromTraining`: the training loop should check this variable every step and if it's true we have to break the training loop, this variable needs to be initialized in constructor to false

I need 2 public function:

* `void ExitFromTraining()`: this function sets `fExitFromTraining` value to true

* `std::vector<Double_t> GetInteractiveTrainingData();`: this function returns the fCurrentEpoch and the training and testing errors. I use the information in `CalculateEstimator` function to calculate
the erros (if I'm not wrong this function calculates exactly what we need). I suggest not using the `CalculateEstimator` function, instead we should calculate exactly the same in this new function. In this way we
can avoid creating the histograms. Or we should set up a flag which can turn of calculating the histograms

## Simulated solution
MyTrain function simulates the training, and calculates "error function". I use the methods above to get the errors or stop the loop.

### python
In python I set the `_threaded` flag for MyTraining, and it runs in a thread and doesn't lock the GIL for whole running time. In main thread I create a button with ipywidgets, if we click on this it will run the `TMVA::MethodMLP::ExitFromTraining()` function. I write to output cell a script call which initializes my drawing class. After this I call in every 500ms an update function which gets new data from TMVA, and insert
to output cell a JavaScript code which call a data inserter method. After the insertion is done, I remove this new data inserter output. I didn't use a Sleeping method for delaying, because that will need a thread
just for waiting and will make the calculation slower. I use `threading.Timer` function which will start a thread after the time passes, and I think this is more efficient then using a Sleep method.


### Javascript
I created the IChart module (comes from InteractiveChart). This function will build the data and plot every changes in a nice way.
